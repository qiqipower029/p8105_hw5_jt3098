p8105\_hw5\_jt3098
================
Jieqi Tu (jt3098)
11/4/2018

Problem 1
---------

``` r
# Create a data frame that contains all file names
longitudinal_data = 
  tibble(list.files(path = "./data"))

# Rename the column name of the first variable
colnames(longitudinal_data)[1] = 'file'
```

``` r
# Create a function to read in files
read_data = function(file) {
  data = 
    read.csv(str_c("./data/", file)) %>%
    as.data.frame()
  
 data
}

# Load files in using created function above
longitudinal_data =
  longitudinal_data %>%
  mutate(data = map(longitudinal_data$file, read_data)) # All data from one file are nested in one variable called "data"
```

``` r
# Spread out the data set
longitudinal_data = 
  longitudinal_data %>%
  unnest() %>% # unnest the `data` variable to obtain more variables to store the data
  gather(key = week, value = value, week_1:week_8) # make week be a single variable

# Separate the control and experiment groups
longitudinal_data = 
  longitudinal_data %>%
  separate(file, into = c("group_type", "number"), sep = "_") %>%
  separate(number, into = c("ID", "extension"), sep = 2) %>%
  select(-extension)

# Manipulate the "week" variable
longitudinal_data = 
  longitudinal_data %>%
  separate(week, into = c("character", "week_number"), sep = 5) %>%
  select(-character)

# Revise the name of arms
longitudinal_data$group_type = str_replace(longitudinal_data$group_type, "con", "control")
longitudinal_data$group_type = str_replace(longitudinal_data$group_type, "exp", "experimental")

# Change the column type of "week_number"
longitudinal_data$week_number = as.numeric(longitudinal_data$week_number)
```

``` r
# Make a new variable for each subject to have a more clear order
longitudinal_data$subject = str_c(longitudinal_data$group_type, '_', longitudinal_data$ID)

# Make a speghetti plot to show the trend of observation data from each arm
longitudinal_data %>%
  ggplot(aes(x = week_number, y = value, group = subject, color = group_type)) +
  geom_line(alpha = 0.5) + 
  geom_point(alpha = 0.2) +
  labs(
    title = "Observations on Each Subject Over Time",
    x = "Week",
    y = "Observation Data"
  ) +
  theme_bw()
```

![](p8105_hw5_jt3098_files/figure-markdown_github/speghetti%20plot%20for%20problem%201-1.png)

Comments: From this plot, we could know that, in general, experimental groups have higher observational values than control groups. Additionally, the overall trend for experimental groups is increasing over time, while there is relatively no big difference in control groups.

Problem 2
---------

``` r
# Importing data for problem 2
homicide_data = read_csv("./data2/homicide-data.csv")
```

``` r
# Calculate the the number of NAs in each column 
n_NA = 
  sapply(homicide_data, function(x) sum(length(which(is.na(x))))) %>%
  knitr::kable()
n_NA
```

|                |    x|
|----------------|----:|
| uid            |    0|
| reported\_date |    0|
| victim\_last   |    0|
| victim\_first  |    0|
| victim\_race   |    0|
| victim\_age    |    0|
| victim\_sex    |    0|
| city           |    0|
| state          |    0|
| lat            |   60|
| lon            |   60|
| disposition    |    0|

Descriptions about the raw data:

-   There are 52179 rows and 12 columns in this dataset.
-   There are 2999 NA values in "victim\_age" variable, and 60 NAs in "lat" and "lon" respectively.
-   This dataset has 52179 observations.
-   The variables inlude ID, reported date, the last and first name of victims, the sex, race and age of victims, the city and state, longitude and latitude, and the deposition status.

``` r
# Make a new variable to summarize the city and state informtion
homicide_data = 
  homicide_data %>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  select(-city, -state)
```

``` r
# Calculate the total number of cases of homicide
homicide_data_summary = 
  homicide_data %>%
  group_by(city_state) %>%
  mutate(n_homicide = n())

# Calculate the total number of unsolved cases
homicide_data_summary = 
  homicide_data_summary %>%
  filter(disposition %in% c("Open/No arrest", "Closed without arrest")) %>%
  group_by(city_state) %>%
  mutate(n_unsolved = n())

# Summarize the total number of cases and unsolved cases by city and state
homicide_data_summary = 
  homicide_data_summary %>%
  distinct(city_state, n_homicide, n_unsolved) %>%
  as.data.frame()

# Check the number of cases and unsolved
homicide_data_summary %>% 
  knitr::kable()
```

| city\_state        |  n\_homicide|  n\_unsolved|
|:-------------------|------------:|------------:|
| Albuquerque, NM    |          378|          146|
| Atlanta, GA        |          973|          373|
| Baltimore, MD      |         2827|         1825|
| Baton Rouge, LA    |          424|          196|
| Birmingham, AL     |          800|          347|
| Boston, MA         |          614|          310|
| Buffalo, NY        |          521|          319|
| Charlotte, NC      |          687|          206|
| Chicago, IL        |         5535|         4073|
| Cincinnati, OH     |          694|          309|
| Columbus, OH       |         1084|          575|
| Dallas, TX         |         1567|          754|
| Denver, CO         |          312|          169|
| Detroit, MI        |         2519|         1482|
| Durham, NC         |          276|          101|
| Fort Worth, TX     |          549|          255|
| Fresno, CA         |          487|          169|
| Houston, TX        |         2942|         1493|
| Indianapolis, IN   |         1322|          594|
| Jacksonville, FL   |         1168|          597|
| Kansas City, MO    |         1190|          486|
| Las Vegas, NV      |         1381|          572|
| Long Beach, CA     |          378|          156|
| Los Angeles, CA    |         2257|         1106|
| Louisville, KY     |          576|          261|
| Memphis, TN        |         1514|          483|
| Miami, FL          |          744|          450|
| Milwaukee, wI      |         1115|          403|
| Minneapolis, MN    |          366|          187|
| Nashville, TN      |          767|          278|
| New Orleans, LA    |         1434|          930|
| New York, NY       |          627|          243|
| Oakland, CA        |          947|          508|
| Oklahoma City, OK  |          672|          326|
| Omaha, NE          |          409|          169|
| Philadelphia, PA   |         3037|         1360|
| Phoenix, AZ        |          914|          504|
| Pittsburgh, PA     |          631|          337|
| Richmond, VA       |          429|          113|
| San Antonio, TX    |          833|          357|
| Sacramento, CA     |          376|          139|
| Savannah, GA       |          246|          115|
| San Bernardino, CA |          275|          170|
| San Diego, CA      |          461|          175|
| San Francisco, CA  |          663|          336|
| St. Louis, MO      |         1677|          905|
| Stockton, CA       |          444|          266|
| Tampa, FL          |          208|           95|
| Tulsa, OK          |          583|          193|
| Washington, DC     |         1345|          589|

``` r
# Make a proportion test for unsolved cases in the total cases
result_Baltimore = 
  prop.test(x = homicide_data_summary$n_unsolved[homicide_data_summary$city_state == "Baltimore, MD"],
            n = homicide_data_summary$n_homicide[homicide_data_summary$city_state == "Baltimore, MD"],
            alternative = "two.sided") # save the output of the prop.test as an R object

# Extract proportion estimate and confidence interval
result_Baltimore_extract = 
  result_Baltimore %>%
  broom::tidy() %>%
  as.data.frame() %>%
  select(estimate, conf.low, conf.high)

result_Baltimore_extract %>% knitr::kable()
```

|   estimate|   conf.low|  conf.high|
|----------:|----------:|----------:|
|  0.6455607|  0.6275625|  0.6631599|

``` r
# Use map2 function to do prop test for each city and get tidied
result_each_city = 
  homicide_data_summary %>%
  mutate(prop_result = map2(.x = n_unsolved, .y = n_homicide, ~broom::tidy(prop.test(.x, .y)))) %>%
  unnest

# Extract the proportion estimate and confidence interval for each city
result_each_city = 
  result_each_city %>%
  select(city_state, estimate, conf.low, conf.high)

result_each_city %>% knitr::kable()
```

| city\_state        |   estimate|   conf.low|  conf.high|
|:-------------------|----------:|----------:|----------:|
| Albuquerque, NM    |  0.3862434|  0.3372604|  0.4375766|
| Atlanta, GA        |  0.3833505|  0.3528119|  0.4148219|
| Baltimore, MD      |  0.6455607|  0.6275625|  0.6631599|
| Baton Rouge, LA    |  0.4622642|  0.4141987|  0.5110240|
| Birmingham, AL     |  0.4337500|  0.3991889|  0.4689557|
| Boston, MA         |  0.5048860|  0.4646219|  0.5450881|
| Buffalo, NY        |  0.6122841|  0.5687990|  0.6540879|
| Charlotte, NC      |  0.2998544|  0.2660820|  0.3358999|
| Chicago, IL        |  0.7358627|  0.7239959|  0.7473998|
| Cincinnati, OH     |  0.4452450|  0.4079606|  0.4831439|
| Columbus, OH       |  0.5304428|  0.5002167|  0.5604506|
| Dallas, TX         |  0.4811742|  0.4561942|  0.5062475|
| Denver, CO         |  0.5416667|  0.4846098|  0.5976807|
| Detroit, MI        |  0.5883287|  0.5687903|  0.6075953|
| Durham, NC         |  0.3659420|  0.3095874|  0.4260936|
| Fort Worth, TX     |  0.4644809|  0.4222542|  0.5072119|
| Fresno, CA         |  0.3470226|  0.3051013|  0.3913963|
| Houston, TX        |  0.5074779|  0.4892447|  0.5256914|
| Indianapolis, IN   |  0.4493192|  0.4223156|  0.4766207|
| Jacksonville, FL   |  0.5111301|  0.4820460|  0.5401402|
| Kansas City, MO    |  0.4084034|  0.3803996|  0.4370054|
| Las Vegas, NV      |  0.4141926|  0.3881284|  0.4407395|
| Long Beach, CA     |  0.4126984|  0.3629026|  0.4642973|
| Los Angeles, CA    |  0.4900310|  0.4692208|  0.5108754|
| Louisville, KY     |  0.4531250|  0.4120609|  0.4948235|
| Memphis, TN        |  0.3190225|  0.2957047|  0.3432691|
| Miami, FL          |  0.6048387|  0.5685783|  0.6400015|
| Milwaukee, wI      |  0.3614350|  0.3333172|  0.3905194|
| Minneapolis, MN    |  0.5109290|  0.4585150|  0.5631099|
| Nashville, TN      |  0.3624511|  0.3285592|  0.3977401|
| New Orleans, LA    |  0.6485356|  0.6231048|  0.6731615|
| New York, NY       |  0.3875598|  0.3494421|  0.4270755|
| Oakland, CA        |  0.5364308|  0.5040588|  0.5685037|
| Oklahoma City, OK  |  0.4851190|  0.4467861|  0.5236245|
| Omaha, NE          |  0.4132029|  0.3653146|  0.4627477|
| Philadelphia, PA   |  0.4478103|  0.4300380|  0.4657157|
| Phoenix, AZ        |  0.5514223|  0.5184825|  0.5839244|
| Pittsburgh, PA     |  0.5340729|  0.4942706|  0.5734545|
| Richmond, VA       |  0.2634033|  0.2228571|  0.3082658|
| San Antonio, TX    |  0.4285714|  0.3947772|  0.4630331|
| Sacramento, CA     |  0.3696809|  0.3211559|  0.4209131|
| Savannah, GA       |  0.4674797|  0.4041252|  0.5318665|
| San Bernardino, CA |  0.6181818|  0.5576628|  0.6753422|
| San Diego, CA      |  0.3796095|  0.3354259|  0.4258315|
| San Francisco, CA  |  0.5067873|  0.4680516|  0.5454433|
| St. Louis, MO      |  0.5396541|  0.5154369|  0.5636879|
| Stockton, CA       |  0.5990991|  0.5517145|  0.6447418|
| Tampa, FL          |  0.4567308|  0.3881009|  0.5269851|
| Tulsa, OK          |  0.3310463|  0.2932349|  0.3711192|
| Washington, DC     |  0.4379182|  0.4112495|  0.4649455|

``` r
# Make a plot to show the estimate and CI for each city
result_each_city %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(alpha = 0.5) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), alpha = 0.4) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, size = 8)) +
  labs(
    title = "Proportion Estimate and CI of Unsolved Homicide in Each City",
    x = "City",
    y = "Proportion Estimate with Confidence Interval"
  ) 
```

![](p8105_hw5_jt3098_files/figure-markdown_github/plotting%20for%20the%20results-1.png)
